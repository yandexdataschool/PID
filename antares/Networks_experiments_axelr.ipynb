{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import root_numpy\n",
    "from hep_ml.nnet import MLPMultiClassifier\n",
    "from rep.metaml import FoldingClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('features.json') as f:\n",
    "    feature_families = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "[u'MuonNShared' u'MuonIsLooseMuon' u'MuonIsMuon' u'MuonBkgLL' u'MuonMuLL'\n",
      " u'TrackFitVeloChi2' u'TrackFitVeloNDoF' u'TrackFitMatchChi2'\n",
      " u'TrackGhostProbability' u'TrackP' u'TrackChi2PerDof' u'TrackFitTChi2'\n",
      " u'TrackPt' u'TrackNumDof' u'TrackFitTNDoF' u'TrackDOCA' u'InAccSpd'\n",
      " u'InAccPrs' u'InAccBrem' u'InAccEcal' u'InAccHcal' u'InAccMuon'\n",
      " u'CombDLLmu' u'CombDLLpi' u'CombDLLp' u'CombDLLe' u'CombDLLk'\n",
      " u'RichAboveMuThres' u'RichAboveElThres' u'RichAbovePiThres'\n",
      " u'RichAboveKaThres' u'RichAbovePrThres' u'RichUsedR1Gas' u'RichUsedR2Gas'\n",
      " u'RichDLLbt' u'RichDLLpi' u'RichDLLe' u'RichDLLp' u'RichDLLmu' u'RichDLLk'\n",
      " u'CaloBremMatch' u'CaloElectronMatch' u'CaloTrMatch' u'CaloTrajectoryL'\n",
      " u'CaloChargedSpd' u'CaloChargedPrs' u'CaloChargedEcal' u'CaloNeutralSpd'\n",
      " u'CaloNeutralPrs' u'CaloNeutralEcal' u'CaloSpdE' u'CaloPrsE' u'CaloEcalE'\n",
      " u'CaloHcalE' u'EcalPIDmu' u'HcalPIDmu' u'PrsPIDe' u'BremPIDe' u'EcalPIDe'\n",
      " u'HcalPIDe']\n"
     ]
    }
   ],
   "source": [
    "train_features = numpy.concatenate(feature_families.values())\n",
    "print len(train_features)\n",
    "print train_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train = pandas.DataFrame(root_numpy.root2array('../data/global_train.root', 'tree', step=10))\n",
    "data_test  = pandas.DataFrame(root_numpy.root2array('../data/global_test.root', 'tree', step=10))\n",
    "\n",
    "from utils import shrink_floats\n",
    "shrink_floats(data_train)\n",
    "shrink_floats(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({-2212: 47733,\n",
       "         -321: 49353,\n",
       "         -211: 50040,\n",
       "         -13: 50197,\n",
       "         -11: 50361,\n",
       "         0: 100002,\n",
       "         11: 49625,\n",
       "         13: 49813,\n",
       "         211: 49974,\n",
       "         321: 50632,\n",
       "         2212: 52270})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(data_train.MCParticleType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VeloCharge</th>\n",
       "      <th>BremPIDe</th>\n",
       "      <th>CaloNeutralPrs</th>\n",
       "      <th>CaloNeutralSpd</th>\n",
       "      <th>InAccBrem</th>\n",
       "      <th>InAccSpd</th>\n",
       "      <th>CaloPrsE</th>\n",
       "      <th>InAccPrs</th>\n",
       "      <th>HcalPIDe</th>\n",
       "      <th>CaloHcalE</th>\n",
       "      <th>...</th>\n",
       "      <th>piplus_OWNPV_XERR</th>\n",
       "      <th>piplus_OWNPV_YERR</th>\n",
       "      <th>piplus_OWNPV_ZERR</th>\n",
       "      <th>piplus_OWNPV_CHI2</th>\n",
       "      <th>piplus_OWNPV_NDOF</th>\n",
       "      <th>piplus_IP_OWNPV</th>\n",
       "      <th>piplus_IPCHI2_OWNPV</th>\n",
       "      <th>nCandidate</th>\n",
       "      <th>totCandidates</th>\n",
       "      <th>EventInSequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.028090</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0532</td>\n",
       "      <td>33.816654</td>\n",
       "      <td>83</td>\n",
       "      <td>0.111340</td>\n",
       "      <td>15.622943</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "      <td>9099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.189990</td>\n",
       "      <td>-0.618836</td>\n",
       "      <td>35.381054</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.873741</td>\n",
       "      <td>1</td>\n",
       "      <td>0.961872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0427</td>\n",
       "      <td>53.822292</td>\n",
       "      <td>123</td>\n",
       "      <td>0.802176</td>\n",
       "      <td>196.415192</td>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "      <td>3135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.183287</td>\n",
       "      <td>-0.082057</td>\n",
       "      <td>13.987859</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0559</td>\n",
       "      <td>34.384235</td>\n",
       "      <td>85</td>\n",
       "      <td>0.061936</td>\n",
       "      <td>1.096196</td>\n",
       "      <td>20</td>\n",
       "      <td>104</td>\n",
       "      <td>10176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.026841</td>\n",
       "      <td>2.711674</td>\n",
       "      <td>9.873783</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50.466003</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.0683</td>\n",
       "      <td>22.266401</td>\n",
       "      <td>49</td>\n",
       "      <td>0.055527</td>\n",
       "      <td>2.439735</td>\n",
       "      <td>7</td>\n",
       "      <td>84</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.158708</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.203873</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.160355</td>\n",
       "      <td>3640.665527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0567</td>\n",
       "      <td>52.799332</td>\n",
       "      <td>123</td>\n",
       "      <td>0.176878</td>\n",
       "      <td>1.941835</td>\n",
       "      <td>57</td>\n",
       "      <td>107</td>\n",
       "      <td>13362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   VeloCharge    BremPIDe  CaloNeutralPrs  CaloNeutralSpd  InAccBrem  \\\n",
       "0    1.028090 -999.000000     -999.000000            -999          0   \n",
       "1    1.189990   -0.618836       35.381054               0          1   \n",
       "2    1.183287   -0.082057       13.987859               0          1   \n",
       "3    1.026841    2.711674        9.873783               0          1   \n",
       "4    1.158708 -999.000000     -999.000000            -999          0   \n",
       "\n",
       "   InAccSpd    CaloPrsE  InAccPrs    HcalPIDe    CaloHcalE       ...         \\\n",
       "0         0 -999.000000         0 -999.000000  -999.000000       ...          \n",
       "1         1  122.873741         1    0.961872     0.000000       ...          \n",
       "2         0 -999.000000         0 -999.000000  -999.000000       ...          \n",
       "3         1   50.466003         1    0.434916     0.000000       ...          \n",
       "4         1   36.203873         1   -1.160355  3640.665527       ...          \n",
       "\n",
       "   piplus_OWNPV_XERR  piplus_OWNPV_YERR  piplus_OWNPV_ZERR  piplus_OWNPV_CHI2  \\\n",
       "0             0.0096             0.0096             0.0532          33.816654   \n",
       "1             0.0089             0.0085             0.0427          53.822292   \n",
       "2             0.0097             0.0097             0.0559          34.384235   \n",
       "3             0.0131             0.0127             0.0683          22.266401   \n",
       "4             0.0083             0.0083             0.0567          52.799332   \n",
       "\n",
       "   piplus_OWNPV_NDOF  piplus_IP_OWNPV  piplus_IPCHI2_OWNPV  nCandidate  \\\n",
       "0                 83         0.111340            15.622943          16   \n",
       "1                123         0.802176           196.415192           2   \n",
       "2                 85         0.061936             1.096196          20   \n",
       "3                 49         0.055527             2.439735           7   \n",
       "4                123         0.176878             1.941835          57   \n",
       "\n",
       "   totCandidates  EventInSequence  \n",
       "0             37             9099  \n",
       "1             71             3135  \n",
       "2            104            10176  \n",
       "3             84              205  \n",
       "4            107            13362  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add signal column (from 0 to 5 classes), weights (to balance data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import compute_labels_and_weights, compute_charges, names_labels_correspondence, labels_names_correspondence\n",
    "from utils import plot_hist_features, roc_auc_score_one_vs_all, compute_cum_sum, convert_DLL_to_LL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train['Signal'], data_train['Weight'] = compute_labels_and_weights(data_train.MCParticleType.values)\n",
    "data_test['Signal'], data_test['Weight'] = compute_labels_and_weights(data_test.MCParticleType.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "muon       5 \t[u'MuonNShared', u'MuonIsLooseMuon', u'MuonIsMuon', u'MuonBkgLL', u'MuonMuLL']\n",
      "track      11 \t[u'TrackFitVeloChi2', u'TrackFitVeloNDoF', u'TrackFitMatchChi2', u'TrackGhostProbability', u'TrackP', u'TrackChi2PerDof', u'TrackFitTChi2', u'TrackPt', u'TrackNumDof', u'TrackFitTNDoF', u'TrackDOCA']\n",
      "acceptance 6 \t[u'InAccSpd', u'InAccPrs', u'InAccBrem', u'InAccEcal', u'InAccHcal', u'InAccMuon']\n",
      "DLL        5 \t[u'CombDLLmu', u'CombDLLpi', u'CombDLLp', u'CombDLLe', u'CombDLLk']\n",
      "RICH       13 \t[u'RichAboveMuThres', u'RichAboveElThres', u'RichAbovePiThres', u'RichAboveKaThres', u'RichAbovePrThres', u'RichUsedR1Gas', u'RichUsedR2Gas', u'RichDLLbt', u'RichDLLpi', u'RichDLLe', u'RichDLLp', u'RichDLLmu', u'RichDLLk']\n",
      "CALO       20 \t[u'CaloBremMatch', u'CaloElectronMatch', u'CaloTrMatch', u'CaloTrajectoryL', u'CaloChargedSpd', u'CaloChargedPrs', u'CaloChargedEcal', u'CaloNeutralSpd', u'CaloNeutralPrs', u'CaloNeutralEcal', u'CaloSpdE', u'CaloPrsE', u'CaloEcalE', u'CaloHcalE', u'EcalPIDmu', u'HcalPIDmu', u'PrsPIDe', u'BremPIDe', u'EcalPIDe', u'HcalPIDe']\n"
     ]
    }
   ],
   "source": [
    "for family_name, family_features in feature_families.items():\n",
    "    print \"{:10}\".format(family_name), len(family_features), '\\t', family_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to print quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import roc_auc_score_one_vs_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 5s, sys: 2.64 s, total: 2min 8s\n",
      "Wall time: 1min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlp_clf = SklearnClassifier(MLPMultiClassifier(layers=[20], epochs=100, scaler='iron'), \n",
    "                            features=train_features)\n",
    "mlp_clf.fit(data_train, data_train.Signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking simple MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 52min 42s, sys: 1h 19min 32s, total: 3h 12min 14s\n",
      "Wall time: 31min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlp_clf = SklearnClassifier(MLPMultiClassifier(layers=[40, 30, 20], epochs=1000, scaler='iron'), \n",
    "                            features=train_features)\n",
    "mlp_clf.fit(data_train, data_train.Signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rep.estimators import SklearnClassifier\n",
    "from hep_ml.nnet import MLPMultiClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 52min 42s, sys: 1h 19min 32s, total: 3h 12min 14s\n",
      "Wall time: 31min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlp_clf = SklearnClassifier(MLPMultiClassifier(layers=[40, 30, 20], epochs=1000, scaler='iron'), \n",
    "                            features=train_features)\n",
    "mlp_clf.fit(data_train, data_train.Signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ghost    0.9579   Electron 0.9889   Muon     0.9908   Pion     0.9538   Kaon     0.9254   Proton   0.9252   \n"
     ]
    }
   ],
   "source": [
    "print_aucs(mlp_clf, data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ghost    0.9583   Electron 0.9893   Muon     0.9912   Pion     0.9544   Kaon     0.9259   Proton   0.9257   \n"
     ]
    }
   ],
   "source": [
    "print_aucs(mlp_clf, data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining one more network over hep_ml.nnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hep_ml.nnet import MLPMultiClassifier, MLPBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano.tensor as T\n",
    "class FamiliesMultiClassifier(MLPMultiClassifier):\n",
    "    \"\"\"\n",
    "    Has two layers = one over each subsystem, and one is global.\n",
    "    \"\"\"\n",
    "    def prepare(self):\n",
    "        print self.layers_\n",
    "        n_input, subsystem_sizes, size2, size3, n_output = self.layers_\n",
    "        \n",
    "        subsystem_offsets = numpy.cumsum([0] + list(subsystem_sizes))\n",
    "        assert n_input == sum(subsystem_sizes) + 1\n",
    "        W1s = []\n",
    "        subsystem_output = 10\n",
    "        for i, subsystem_size in enumerate(subsystem_sizes):\n",
    "            W1s.append(self._create_matrix_parameter('W1_{}'.format(i), subsystem_size + 1, subsystem_output))\n",
    "        W2 = self._create_matrix_parameter('W2', subsystem_output * len(subsystem_sizes), size2)\n",
    "        W3 = self._create_matrix_parameter('W3', size2, size3)\n",
    "        W4 = self._create_matrix_parameter('W4', size3, n_output)\n",
    "\n",
    "        def my_activation(x):\n",
    "            outputs = []\n",
    "            for i, W1_ in enumerate(W1s):\n",
    "                features_range = list(numpy.arange(subsystem_offsets[i], subsystem_offsets[i+1])) + [n_input - 1]\n",
    "                # print 'features_range', features_range\n",
    "                output = T.tanh(T.dot(x[:, features_range], W1_))\n",
    "                outputs.append(output)\n",
    "\n",
    "            layer1 = T.concatenate(outputs, axis=1)\n",
    "            layer2 = T.tanh(T.dot(layer1, W2))\n",
    "            layer3 = T.tanh(T.dot(layer2, W3))\n",
    "            layer4 = T.dot(layer3, W4)\n",
    "            return layer4    \n",
    "                \n",
    "\n",
    "        return my_activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[61, [5, 11, 6, 5, 13, 20], 30, 20, 6]\n",
      "CPU times: user 3h 35min 45s, sys: 1h 53min 22s, total: 5h 29min 8s\n",
      "Wall time: 2h 59min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "layers = [[len(x) for x in feature_families.values()], 30, 20]\n",
    "fmc_clf = SklearnClassifier(FamiliesMultiClassifier(layers=layers, epochs=1000, scaler='iron'), \n",
    "                            features=train_features)\n",
    "fmc_clf.fit(data_train, data_train.Signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle\n",
    "# with open('./structured_NN.pkl', 'w') as f:\n",
    "#     cPickle.dump(fmc_clf, f)\n",
    "\n",
    "with open('./structured_NN.pkl') as f:\n",
    "    fmc_clf = cPickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decision_function(self, X):\n",
    "    \"\"\"\n",
    "    Activates NN on particular dataset\n",
    "\n",
    "    :param numpy.array X: of shape [n_samples, n_features]\n",
    "    :return: numpy.array with results of shape [n_samples]\n",
    "    \"\"\"\n",
    "    X = self._transform(X, fit=False).astype('float32')\n",
    "    return self.Activation(X)\n",
    "    \n",
    "FamiliesMultiClassifier.decision_function = decision_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ghost    0.9575   Electron 0.9885   Muon     0.9905   Pion     0.9529   Kaon     0.9244   Proton   0.9242   \n"
     ]
    }
   ],
   "source": [
    "print_aucs(fmc_clf, data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ghost    0.9578   Electron 0.9889   Muon     0.9908   Pion     0.9533   Kaon     0.9247   Proton   0.9246   \n"
     ]
    }
   ],
   "source": [
    "print_aucs(fmc_clf, data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras\n",
    "\n",
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hep_ml.preprocessing import IronTransformer\n",
    "\n",
    "scaler = IronTransformer(symmetrize=True)\n",
    "scaler.fit(data_train[train_features])\n",
    "new_trainX = scaler.transform(data_train[train_features])\n",
    "trainY = data_train.Signal.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "st_scaler = StandardScaler()\n",
    "st_scaler.fit(data_train[train_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single layer with StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(150, input_dim=len(train_features)))\n",
    "model.add(Activation('tanh'))\n",
    "\n",
    "n_classes = len(set(trainY))\n",
    "model.add(Dense(n_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "keras_no_iron_clf = model\n",
    "keras_no_iron_clf.compile(loss='categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "CPU times: user 23min 49s, sys: 1h 6min 14s, total: 1h 30min 3s\n",
      "Wall time: 13min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "keras_no_iron_predictions = []\n",
    "\n",
    "\n",
    "for epochs in range(15):\n",
    "    keras_no_iron_clf.fit(st_scaler.transform(data_train[train_features]), np_utils.to_categorical(trainY), \n",
    "                          verbose=0, nb_epoch=5, batch_size=256)\n",
    "    print 'done'\n",
    "    keras_no_iron_predictions.append(keras_no_iron_clf.predict_proba(st_scaler.transform(data_test[train_features]), verbose=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.95233476  0.98731826  0.98792387  0.94891918  0.92129942  0.92129873]]\n",
      "[[ 0.95500032  0.98795841  0.98895797  0.95065482  0.9244877   0.92369024]]\n",
      "[[ 0.95611325  0.98817854  0.98942338  0.95183913  0.92432307  0.92495718]]\n",
      "[[ 0.9565099   0.98831205  0.9896617   0.95231596  0.92557563  0.92567358]]\n",
      "[[ 0.95704975  0.98869146  0.98993983  0.95198752  0.92566623  0.92555023]]\n",
      "[[ 0.95800668  0.98871423  0.99003609  0.9525334   0.92488414  0.924423  ]]\n",
      "[[ 0.95753114  0.98845578  0.99005091  0.95306655  0.92697531  0.92676571]]\n",
      "[[ 0.95824846  0.98887089  0.99015913  0.95308091  0.92618218  0.92606379]]\n",
      "[[ 0.958308    0.98862266  0.99009165  0.95297046  0.9269928   0.92668938]]\n",
      "[[ 0.95812997  0.98850111  0.99013517  0.95280935  0.92654768  0.92696559]]\n",
      "[[ 0.9580592   0.98893064  0.99014577  0.95322719  0.92685258  0.9271297 ]]\n",
      "[[ 0.95856254  0.98911537  0.99026655  0.95354437  0.92668991  0.92684252]]\n",
      "[[ 0.95736746  0.98886616  0.99040561  0.95342798  0.92700319  0.92688933]]\n",
      "[[ 0.95857972  0.98917833  0.99028331  0.95363517  0.92672214  0.92715774]]\n",
      "[[ 0.95821284  0.98915355  0.99038531  0.95311644  0.92700788  0.92759611]]\n"
     ]
    }
   ],
   "source": [
    "for p in keras_no_iron_predictions:\n",
    "    print roc_auc_score_one_vs_all(data_test.Signal, p, data_test.Weight).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(150, input_dim=len(train_features)))\n",
    "model.add(Activation('tanh'))\n",
    "\n",
    "n_classes = len(set(trainY))\n",
    "model.add(Dense(n_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "keras_onelayer_clf = model\n",
    "keras_onelayer_clf.compile(loss='categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "CPU times: user 6min 17s, sys: 15min 58s, total: 22min 16s\n",
      "Wall time: 3min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# keras_onelayer_predictions = []\n",
    "for epochs in range(15):\n",
    "    keras_onelayer_clf.fit(new_trainX.values, np_utils.to_categorical(trainY), \n",
    "                           verbose=0, nb_epoch=5, batch_size=256)\n",
    "    print 'done'\n",
    "    keras_onelayer_predictions.append(keras_onelayer_clf.predict_proba(scaler.transform(data_test[train_features]).values, verbose=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.95666376  0.98789876  0.99014538  0.95192405  0.92033015  0.91941495]]\n",
      "[[ 0.95825367  0.9886869   0.99079318  0.95346667  0.92338571  0.92270784]]\n",
      "[[ 0.95856513  0.98895444  0.99103536  0.95387046  0.92436585  0.92385327]]\n",
      "[[ 0.95869598  0.98915723  0.99116502  0.95457781  0.9248634   0.92391089]]\n",
      "[[ 0.95890223  0.98922488  0.99124332  0.9547234   0.924765    0.9239011 ]]\n",
      "[[ 0.95869938  0.98940489  0.99131735  0.95493054  0.92508832  0.92518813]]\n",
      "[[ 0.95887798  0.98937772  0.99140583  0.955043    0.92521522  0.92502914]]\n",
      "[[ 0.95881337  0.98935549  0.99134941  0.95493522  0.92499898  0.92494409]]\n",
      "[[ 0.95880484  0.9894924   0.99136138  0.95512026  0.92552391  0.92491172]]\n",
      "[[ 0.95878197  0.98964464  0.99153951  0.95507195  0.92554708  0.92586741]]\n",
      "[[ 0.95905589  0.98973771  0.99154188  0.95508617  0.92531566  0.9256772 ]]\n",
      "[[ 0.95899474  0.98973991  0.99152305  0.95497449  0.92575512  0.92546164]]\n",
      "[[ 0.95875155  0.98972273  0.99155035  0.95507517  0.92550633  0.92568639]]\n",
      "[[ 0.95896605  0.98980521  0.99138075  0.95509762  0.92565189  0.92572042]]\n",
      "[[ 0.95835047  0.9897201   0.99156272  0.95489142  0.9260902   0.9257949 ]]\n"
     ]
    }
   ],
   "source": [
    "for p in keras_onelayer_predictions:\n",
    "    print roc_auc_score_one_vs_all(data_test.Signal, p, data_test.Weight).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_predictions(keras_onelayer_clf.predict_proba(scaler.transform(data_test_full[train_features]).values, verbose=0), \n",
    "                 filename='./models/keras_onelayer_probs.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 420 ms, sys: 0 ns, total: 420 ms\n",
      "Wall time: 418 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(300, input_dim=len(train_features)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(300))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(400))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "n_classes = len(set(trainY))\n",
    "\n",
    "model.add(Dense(n_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "keras_dl_clf = model\n",
    "keras_dl_clf.compile(loss='categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keras_dl_predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Refreshing lock /home/robot-cern-ipcluster/.theano/compiledir_Linux-3.2--virtual-x86_64-with-debian-wheezy-sid-x86_64-2.7.11-64/lock_dir/lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "CPU times: user 2h 12min 14s, sys: 3h 58min 21s, total: 6h 10min 35s\n",
      "Wall time: 53min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epochs in range(5):\n",
    "    keras_dl_clf.fit(new_trainX.values, np_utils.to_categorical(trainY), \n",
    "                     verbose=0, nb_epoch=10, batch_size=256)\n",
    "    print 'done'\n",
    "    keras_dl_predictions.append(keras_dl_clf.predict_proba(scaler.transform(data_test[train_features]).values, verbose=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.95974343  0.98996496  0.99166346  0.95572337  0.92788679  0.92757497]]\n",
      "[[ 0.96042376  0.99017225  0.99178153  0.9561138   0.92778428  0.92742485]]\n",
      "[[ 0.96053858  0.99026935  0.99192785  0.95622811  0.92860987  0.92815673]]\n",
      "[[ 0.96039781  0.9903791   0.9917358   0.95620892  0.92882523  0.92873579]]\n",
      "[[ 0.96018208  0.9902056   0.99181709  0.95599073  0.92882642  0.92868044]]\n"
     ]
    }
   ],
   "source": [
    "for p in keras_dl_predictions:\n",
    "    print roc_auc_score_one_vs_all(data_test.Signal, p, data_test.Weight).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_predictions(keras_dl_clf.predict_proba(scaler.transform(data_test_full[train_features]).values, verbose=False),\n",
    "                 filename='./models/keras_dl_probs.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras with sublayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Layer\n",
    "from keras import backend as K\n",
    "\n",
    "class Sublayer(Layer):\n",
    "    def __init__(self, sizes, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        self.sizes = sizes\n",
    "        super(Sublayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_dim = input_shape[1]\n",
    "        self.trainable_weights = []\n",
    "        for i in range(len(self.sizes) - 1):\n",
    "            matrix_size = (self.sizes[i+1] - self.sizes[i], self.output_dim)\n",
    "            initial_weight_value = numpy.random.random(size=matrix_size)\n",
    "            W = K.variable(initial_weight_value)\n",
    "            self.trainable_weights.append(W)\n",
    "            print matrix_size\n",
    "        self.trainable_weights.append(K.zeros((self.output_dim * (len(self.sizes) - 1),)))\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        sublayers_outputs = []\n",
    "        assert len(self.trainable_weights) == (len(self.sizes) - 1) + 1\n",
    "        for i in range(len(self.sizes) - 1):\n",
    "            w = self.trainable_weights[i]\n",
    "            sublayers_outputs.append(K.dot(x[:, self.sizes[i]:self.sizes[i+1]], w))\n",
    "   \n",
    "        return K.concatenate(sublayers_outputs, axis=1) + self.trainable_weights[-1]\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim * (len(self.sizes) - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from theano import tensor\n",
    "from keras.layers import InputLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  5 16 22 27 40 60]\n",
      "(5, 50)\n",
      "(11, 50)\n",
      "(6, 50)\n",
      "(5, 50)\n",
      "(13, 50)\n",
      "(20, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/moosefs/miniconda/envs/ipython_py2/lib/python2.7/site-packages/keras/engine/topology.py:1537: UserWarning: Model inputs must come from a Keras Input layer, they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to \"sequential_38_model\" was not an Input tensor, it was generated by layer activation_67.\n",
      "Note that input tensors are instantiated via `tensor = Input(shape)`.\n",
      "The tensor that caused the issue was: activation_input_19\n",
      "  str(x.name))\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Activation('linear', input_shape=[len(train_features)]))\n",
    "\n",
    "sublayer_sizes = numpy.cumsum([0] + map(len, feature_families.values()))\n",
    "print sublayer_sizes\n",
    "model.add(Sublayer(sizes=sublayer_sizes, output_dim=50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(300))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(400))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "n_classes = len(set(trainY))\n",
    "\n",
    "model.add(Dense(n_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "keras_clf = model\n",
    "keras_clf.compile(loss='categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "keras_predictions = []\n",
    "for epochs in range(10):\n",
    "    model.fit(new_trainX.values, np_utils.to_categorical(trainY), verbose=0, nb_epoch=10, batch_size=256)\n",
    "    print 'done'\n",
    "    keras_predictions.append(keras_clf.predict_proba(scaler.transform(data_test[train_features]).values, verbose=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.95964446  0.98971659  0.99164872  0.95547135  0.92751891  0.92765897]]\n",
      "[[ 0.9603116   0.99011257  0.9919267   0.95603929  0.92908952  0.92911864]]\n",
      "[[ 0.96005068  0.99034869  0.99200285  0.95633263  0.92905454  0.92911523]]\n",
      "[[ 0.96066451  0.99034355  0.99216775  0.95652334  0.92893074  0.92861009]]\n",
      "[[ 0.96060343  0.99034118  0.99216024  0.95665133  0.92935868  0.92960834]]\n",
      "[[ 0.96077933  0.99041443  0.99211987  0.95658752  0.92937758  0.92896074]]\n",
      "[[ 0.9609456   0.99043873  0.99217464  0.95680104  0.92934219  0.92931343]]\n",
      "[[ 0.96097054  0.99052944  0.99211185  0.95658635  0.92962384  0.92949816]]\n",
      "[[ 0.96102828  0.99051049  0.99222165  0.9568887   0.92923975  0.92946643]]\n",
      "[[ 0.96102772  0.99047985  0.992204    0.95684819  0.92945688  0.92970952]]\n"
     ]
    }
   ],
   "source": [
    "for p in keras_predictions:\n",
    "    print roc_auc_score_one_vs_all(data_test.Signal, p, data_test.Weight).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.95775714  0.98907129  0.99090353  0.95334663  0.92528597  0.92551847]]\n",
      "[[ 0.95838697  0.98871884  0.99139109  0.95328123  0.92619441  0.92669809]]\n",
      "[[ 0.95789139  0.98923812  0.99132039  0.95331727  0.92627813  0.92604281]]\n",
      "[[ 0.95790181  0.9889717   0.99141375  0.95357187  0.92620091  0.92653914]]\n",
      "[[ 0.9582516   0.98949188  0.99160778  0.95323862  0.92664485  0.92682461]]\n",
      "[[ 0.95855145  0.98919276  0.99143765  0.95316899  0.9263546   0.92672128]]\n",
      "[[ 0.95795853  0.9891986   0.99124588  0.95266372  0.92678905  0.92695552]]\n",
      "[[ 0.95783303  0.98927905  0.99122803  0.95309603  0.92581961  0.92636813]]\n",
      "[[ 0.95784982  0.98906583  0.99137406  0.95246268  0.92587585  0.92604555]]\n",
      "[[ 0.95757006  0.98913391  0.99114323  0.95295626  0.92545959  0.92614058]]\n"
     ]
    }
   ],
   "source": [
    "for p in keras_predictions:\n",
    "    print roc_auc_score_one_vs_all(data_test.Signal, p, data_test.Weight).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_test_full  = pandas.DataFrame(root_numpy.root2array('../data/global_test.root', 'tree', step=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = keras_clf.predict_proba(scaler.transform(data_test_full[train_features]).values, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5999990, 6)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_predictions(predictions, filename):\n",
    "    import cPickle\n",
    "    saved_predictions = {\n",
    "        i: predictions[:, i] for i in range(6)\n",
    "    }\n",
    "    with open(filename, 'w') as f:\n",
    "        cPickle.dump(saved_predictions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle\n",
    "\n",
    "with open('models/keras_sublayers_probs.pkl', 'w') as f:\n",
    "    cPickle.dump(saved_predictions, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras for staged training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_model(input_dim, hidden_layer):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_layer, input_dim=input_dim))\n",
    "    # added dropout not to care about folding :)\n",
    "    model.add(Dropout(p=0.3))\n",
    "    model.add(Activation('tanh'))\n",
    "\n",
    "    n_classes = len(set(trainY))\n",
    "    model.add(Dense(n_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    keras_onelayer_clf = model\n",
    "    keras_onelayer_clf.compile(loss='categorical_crossentropy', optimizer=Adam())\n",
    "    return keras_onelayer_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "CPU times: user 8min 28s, sys: 4.25 s, total: 8min 32s\n",
      "Wall time: 8min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "family_models = {}\n",
    "for family_name, family_features in feature_families.items():\n",
    "    family_model = return_model(len(family_features), hidden_layer=50)\n",
    "    family_models[family_name] = family_model\n",
    "    family_model.fit(new_trainX[family_features].values, np_utils.to_categorical(trainY), \n",
    "                     verbose=0, nb_epoch=20, batch_size=256)\n",
    "    print 'done'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Refreshing lock /home/robot-cern-ipcluster/.theano/compiledir_Linux-3.2--virtual-x86_64-with-debian-wheezy-sid-x86_64-2.7.11-64/lock_dir/lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.58331568  0.58943212  0.90738164  0.57859622  0.58123283  0.58869806]]\n",
      "[[ 0.94679791  0.66227856  0.7793344   0.70914952  0.68253539  0.68137853]]\n",
      "[[ 0.64807595  0.54112762  0.5890995   0.52057345  0.55321033  0.55598696]]\n",
      "[[ 0.75520392  0.97438949  0.95504411  0.91173726  0.89168561  0.88275535]]\n",
      "[[ 0.78141717  0.91491749  0.89614387  0.88260449  0.88270334  0.87715549]]\n",
      "[[ 0.76730805  0.95250696  0.91187955  0.70156456  0.72602407  0.72978713]]\n"
     ]
    }
   ],
   "source": [
    "for family_name, family_features in feature_families.items():\n",
    "    family_model = family_models[family_name]\n",
    "    test_pred = family_model.predict_proba(scaler.transform(data_test[train_features])[family_features].values, verbose=False)\n",
    "    print roc_auc_score_one_vs_all(data_test.Signal, test_pred, data_test.Weight).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joint_train = [scaler.transform(data_train[train_features])]\n",
    "joint_test  = [scaler.transform(data_test_full[train_features])]\n",
    "for family_name, family_features in feature_families.items():\n",
    "    family_model = family_models[family_name]\n",
    "    train_pred = family_model.predict_proba(scaler.transform(data_train[train_features])[family_features].values, verbose=False)\n",
    "    test_pred  = family_model.predict_proba(scaler.transform(data_test_full[train_features])[family_features].values, verbose=False)\n",
    "    joint_train.append(pandas.DataFrame(train_pred))\n",
    "    joint_test.append(pandas.DataFrame(test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_full = pandas.concat(joint_train, axis=1)\n",
    "test_full  = pandas.concat(joint_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(300, input_dim=train_full.shape[1]))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(400))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "n_classes = len(set(trainY))\n",
    "\n",
    "model.add(Dense(n_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "keras_combiner_clf = model\n",
    "keras_combiner_clf.compile(loss='categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "# keras_combiner_predictions = []\n",
    "for epochs in range(3):\n",
    "    keras_combiner_clf.fit(train_full.values, np_utils.to_categorical(trainY), verbose=0, nb_epoch=5, batch_size=256)\n",
    "    print 'done'\n",
    "    keras_combiner_predictions.append(keras_combiner_clf.predict_proba(test_full.values, verbose=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.95986957  0.98978866  0.99152842  0.95515659  0.92808501  0.92790364]]\n"
     ]
    }
   ],
   "source": [
    "for p in keras_combiner_predictions:\n",
    "    print roc_auc_score_one_vs_all(data_test_full.Signal, p, data_test_full.Weight).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_predictions(keras_combiner_predictions[0], './models/keras_subdetectors_probs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
