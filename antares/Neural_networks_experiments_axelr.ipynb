{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import root_numpy\n",
    "from hep_ml.nnet import MLPMultiClassifier\n",
    "from rep.metaml import FoldingClassifier\n",
    "from rep.estimators import SklearnClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('features.json') as f:\n",
    "    feature_families = json.load(f)\n",
    "pv_features = feature_families.pop('PV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "[u'MuonNShared' u'MuonIsLooseMuon' u'MuonIsMuon' u'MuonBkgLL' u'MuonMuLL'\n",
      " u'TrackFitVeloChi2' u'TrackFitVeloNDoF' u'TrackFitMatchChi2'\n",
      " u'TrackGhostProbability' u'TrackP' u'TrackChi2PerDof' u'TrackFitTChi2'\n",
      " u'TrackPt' u'TrackNumDof' u'TrackFitTNDoF' u'TrackDOCA' u'InAccSpd'\n",
      " u'InAccPrs' u'InAccBrem' u'InAccEcal' u'InAccHcal' u'InAccMuon'\n",
      " u'CombDLLmu' u'CombDLLpi' u'CombDLLp' u'CombDLLe' u'CombDLLk'\n",
      " u'RichAboveMuThres' u'RichAboveElThres' u'RichAbovePiThres'\n",
      " u'RichAboveKaThres' u'RichAbovePrThres' u'RichUsedR1Gas' u'RichUsedR2Gas'\n",
      " u'RichDLLbt' u'RichDLLpi' u'RichDLLe' u'RichDLLp' u'RichDLLmu' u'RichDLLk'\n",
      " u'CaloBremMatch' u'CaloElectronMatch' u'CaloTrMatch' u'CaloTrajectoryL'\n",
      " u'CaloChargedSpd' u'CaloChargedPrs' u'CaloChargedEcal' u'CaloNeutralSpd'\n",
      " u'CaloNeutralPrs' u'CaloNeutralEcal' u'CaloSpdE' u'CaloPrsE' u'CaloEcalE'\n",
      " u'CaloHcalE' u'EcalPIDmu' u'HcalPIDmu' u'PrsPIDe' u'BremPIDe' u'EcalPIDe'\n",
      " u'HcalPIDe']\n"
     ]
    }
   ],
   "source": [
    "train_features = numpy.concatenate(feature_families.values())\n",
    "print len(train_features)\n",
    "print train_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import shrink_floats\n",
    "\n",
    "data_train = pandas.DataFrame(root_numpy.root2array('../data/global_train.root', 'tree', step=1))\n",
    "shrink_floats(data_train)\n",
    "\n",
    "data_test_full  = pandas.DataFrame(root_numpy.root2array('../data/global_test.root', 'tree', step=1))\n",
    "shrink_floats(data_test_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating synonyms\n",
    "data_test = data_test_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({-2212: 481659,\n",
       "         -321: 493085,\n",
       "         -211: 499043,\n",
       "         -13: 499794,\n",
       "         -11: 501496,\n",
       "         0: 999995,\n",
       "         11: 498508,\n",
       "         13: 500207,\n",
       "         211: 500963,\n",
       "         321: 506908,\n",
       "         2212: 518335})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(data_train.MCParticleType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VeloCharge</th>\n",
       "      <th>BremPIDe</th>\n",
       "      <th>CaloNeutralPrs</th>\n",
       "      <th>CaloNeutralSpd</th>\n",
       "      <th>InAccBrem</th>\n",
       "      <th>InAccSpd</th>\n",
       "      <th>CaloPrsE</th>\n",
       "      <th>InAccPrs</th>\n",
       "      <th>HcalPIDe</th>\n",
       "      <th>CaloHcalE</th>\n",
       "      <th>...</th>\n",
       "      <th>piplus_OWNPV_XERR</th>\n",
       "      <th>piplus_OWNPV_YERR</th>\n",
       "      <th>piplus_OWNPV_ZERR</th>\n",
       "      <th>piplus_OWNPV_CHI2</th>\n",
       "      <th>piplus_OWNPV_NDOF</th>\n",
       "      <th>piplus_IP_OWNPV</th>\n",
       "      <th>piplus_IPCHI2_OWNPV</th>\n",
       "      <th>nCandidate</th>\n",
       "      <th>totCandidates</th>\n",
       "      <th>EventInSequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.028090</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0532</td>\n",
       "      <td>33.816654</td>\n",
       "      <td>83</td>\n",
       "      <td>0.111340</td>\n",
       "      <td>15.622943</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "      <td>9099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.044008</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0358</td>\n",
       "      <td>67.432457</td>\n",
       "      <td>187</td>\n",
       "      <td>0.025907</td>\n",
       "      <td>0.510528</td>\n",
       "      <td>38</td>\n",
       "      <td>106</td>\n",
       "      <td>12220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.853933</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>155.237808</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.926180</td>\n",
       "      <td>27002.507812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>29.747982</td>\n",
       "      <td>67</td>\n",
       "      <td>0.136919</td>\n",
       "      <td>5.520920</td>\n",
       "      <td>14</td>\n",
       "      <td>76</td>\n",
       "      <td>8573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.306180</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.793685</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>45.295311</td>\n",
       "      <td>97</td>\n",
       "      <td>0.572526</td>\n",
       "      <td>2.692502</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>13449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.969101</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>113.548508</td>\n",
       "      <td>1</td>\n",
       "      <td>1.788384</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0773</td>\n",
       "      <td>33.635342</td>\n",
       "      <td>71</td>\n",
       "      <td>0.101532</td>\n",
       "      <td>4.014179</td>\n",
       "      <td>24</td>\n",
       "      <td>86</td>\n",
       "      <td>1379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   VeloCharge  BremPIDe  CaloNeutralPrs  CaloNeutralSpd  InAccBrem  InAccSpd  \\\n",
       "0    1.028090      -999            -999            -999          0         0   \n",
       "1    1.044008      -999            -999            -999          0         0   \n",
       "2    0.853933      -999            -999            -999          0         1   \n",
       "3    1.306180      -999            -999            -999          0         1   \n",
       "4    0.969101      -999            -999            -999          0         1   \n",
       "\n",
       "     CaloPrsE  InAccPrs    HcalPIDe     CaloHcalE       ...         \\\n",
       "0 -999.000000         0 -999.000000   -999.000000       ...          \n",
       "1 -999.000000         0 -999.000000   -999.000000       ...          \n",
       "2  155.237808         1   -1.926180  27002.507812       ...          \n",
       "3   11.793685         1    0.434916      0.000000       ...          \n",
       "4  113.548508         1    1.788384      0.000000       ...          \n",
       "\n",
       "   piplus_OWNPV_XERR  piplus_OWNPV_YERR  piplus_OWNPV_ZERR  piplus_OWNPV_CHI2  \\\n",
       "0             0.0096             0.0096             0.0532          33.816654   \n",
       "1             0.0064             0.0063             0.0358          67.432457   \n",
       "2             0.0108             0.0108             0.0557          29.747982   \n",
       "3             0.0086             0.0084             0.0453          45.295311   \n",
       "4             0.0115             0.0110             0.0773          33.635342   \n",
       "\n",
       "   piplus_OWNPV_NDOF  piplus_IP_OWNPV  piplus_IPCHI2_OWNPV  nCandidate  \\\n",
       "0                 83         0.111340            15.622943          16   \n",
       "1                187         0.025907             0.510528          38   \n",
       "2                 67         0.136919             5.520920          14   \n",
       "3                 97         0.572526             2.692502          25   \n",
       "4                 71         0.101532             4.014179          24   \n",
       "\n",
       "   totCandidates  EventInSequence  \n",
       "0             37             9099  \n",
       "1            106            12220  \n",
       "2             76             8573  \n",
       "3             50            13449  \n",
       "4             86             1379  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add signal column (from 0 to 5 classes), weights (to balance data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import compute_labels_and_weights, compute_charges, names_labels_correspondence, labels_names_correspondence\n",
    "from utils import plot_hist_features, roc_auc_score_one_vs_all, compute_cum_sum, convert_DLL_to_LL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train['Signal'], data_train['Weight'] = compute_labels_and_weights(data_train.MCParticleType.values)\n",
    "data_test['Signal'], data_test['Weight'] = compute_labels_and_weights(data_test.MCParticleType.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "muon       5 \t[u'MuonNShared', u'MuonIsLooseMuon', u'MuonIsMuon', u'MuonBkgLL', u'MuonMuLL']\n",
      "track      11 \t[u'TrackFitVeloChi2', u'TrackFitVeloNDoF', u'TrackFitMatchChi2', u'TrackGhostProbability', u'TrackP', u'TrackChi2PerDof', u'TrackFitTChi2', u'TrackPt', u'TrackNumDof', u'TrackFitTNDoF', u'TrackDOCA']\n",
      "acceptance 6 \t[u'InAccSpd', u'InAccPrs', u'InAccBrem', u'InAccEcal', u'InAccHcal', u'InAccMuon']\n",
      "DLL        5 \t[u'CombDLLmu', u'CombDLLpi', u'CombDLLp', u'CombDLLe', u'CombDLLk']\n",
      "RICH       13 \t[u'RichAboveMuThres', u'RichAboveElThres', u'RichAbovePiThres', u'RichAboveKaThres', u'RichAbovePrThres', u'RichUsedR1Gas', u'RichUsedR2Gas', u'RichDLLbt', u'RichDLLpi', u'RichDLLe', u'RichDLLp', u'RichDLLmu', u'RichDLLk']\n",
      "CALO       20 \t[u'CaloBremMatch', u'CaloElectronMatch', u'CaloTrMatch', u'CaloTrajectoryL', u'CaloChargedSpd', u'CaloChargedPrs', u'CaloChargedEcal', u'CaloNeutralSpd', u'CaloNeutralPrs', u'CaloNeutralEcal', u'CaloSpdE', u'CaloPrsE', u'CaloEcalE', u'CaloHcalE', u'EcalPIDmu', u'HcalPIDmu', u'PrsPIDe', u'BremPIDe', u'EcalPIDe', u'HcalPIDe']\n"
     ]
    }
   ],
   "source": [
    "for family_name, family_features in feature_families.items():\n",
    "    print \"{:10}\".format(family_name), len(family_features), '\\t', family_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_predictions(predictions, filename):\n",
    "    \"\"\"\n",
    "    Saving predictions on the format appropriate for Tatiana.\n",
    "    \"\"\"\n",
    "    import cPickle\n",
    "    saved_predictions = {\n",
    "        i: predictions[:, i] for i in range(6)\n",
    "    }\n",
    "    with open(filename, 'w') as f:\n",
    "        cPickle.dump(saved_predictions, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to print quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import roc_auc_score_one_vs_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One layer MLP hep_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "mlp_clf = SklearnClassifier(MLPMultiClassifier(layers=[20], epochs=1000, scaler='iron'), \n",
    "                            features=train_features)\n",
    "mlp_clf.fit(data_train, data_train.Signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roc_auc_score_one_vs_all(data_test.Signal, mlp_clf.predict_proba(data_test), data_test.Weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roc_auc_score_one_vs_all(data_train.Signal, mlp_clf.predict_proba(data_train), data_train.Weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking simple MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "mlp_clf = SklearnClassifier(MLPMultiClassifier(layers=[40, 30, 20], epochs=1000, scaler='iron'), \n",
    "                            features=train_features)\n",
    "mlp_clf.fit(data_train, data_train.Signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roc_auc_score_one_vs_all(data_test.Signal, mlp_clf.predict_proba(data_test), data_test.Weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roc_auc_score_one_vs_all(data_train.Signal, mlp_clf.predict_proba(data_train), data_train.Weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining one more network over hep_ml.nnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hep_ml.nnet import MLPMultiClassifier, MLPBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano.tensor as T\n",
    "from hep_ml.nnet import theano, floatX\n",
    "class FamiliesMultiClassifier(MLPMultiClassifier):\n",
    "    \"\"\"\n",
    "    Has two layers = one over each subsystem, and one is global.\n",
    "    \"\"\"\n",
    "    def prepare(self):\n",
    "        print self.layers_\n",
    "        n_input, subsystem_sizes, size2, size3, n_output = self.layers_\n",
    "        \n",
    "        subsystem_offsets = numpy.cumsum([0] + list(subsystem_sizes))\n",
    "        assert n_input == sum(subsystem_sizes) + 1\n",
    "        W1s = []\n",
    "        subsystem_output = 10\n",
    "        hidden1_size = subsystem_output * len(subsystem_sizes)\n",
    "        for i, subsystem_size in enumerate(subsystem_sizes):\n",
    "            W1s.append(self._create_matrix_parameter('W1_{}'.format(i), subsystem_size, subsystem_output))\n",
    "        W2 = self._create_matrix_parameter('W2', hidden1_size, size2)\n",
    "        W3 = self._create_matrix_parameter('W3', size2, size3)\n",
    "        W4 = self._create_matrix_parameter('W4', size3, n_output)\n",
    "\n",
    "        shift = theano.shared(value=self.random_state_.normal(size=[hidden1_size]).astype(floatX) * 0.01, name='shift')\n",
    "        self.parameters['shift'] = shift\n",
    "\n",
    "        def my_activation(x):\n",
    "            outputs = []\n",
    "            for i, W1_ in enumerate(W1s):\n",
    "                output = T.dot(x[:, subsystem_offsets[i]:subsystem_offsets[i + 1]], W1_)\n",
    "                outputs.append(output)\n",
    "\n",
    "            layer1 = T.tanh(T.concatenate(outputs, axis=1) + shift)\n",
    "            layer2 = T.tanh(T.dot(layer1, W2))\n",
    "            layer3 = T.tanh(T.dot(layer2, W3))\n",
    "            layer4 = T.dot(layer3, W4)\n",
    "            return layer4    \n",
    "                \n",
    "        return my_activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "layers = [[len(x) for x in feature_families.values()], 30, 20]\n",
    "fmc_clf = SklearnClassifier(FamiliesMultiClassifier(layers=layers, epochs=1000, scaler='iron'), \n",
    "                            features=train_features)\n",
    "fmc_clf.fit(data_train, data_train.Signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roc_auc_score_one_vs_all(data_test.Signal, fmc_clf.predict_proba(data_test), data_test.Weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roc_auc_score_one_vs_all(data_train.Signal, fmc_clf.predict_proba(data_train), data_train.Weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "\n",
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hep_ml.preprocessing import IronTransformer\n",
    "\n",
    "iron_scaler = IronTransformer(symmetrize=True)\n",
    "iron_scaler.fit(data_train[train_features])\n",
    "\n",
    "ironed_trainX = iron_scaler.transform(data_train[train_features]).values.astype('float32')\n",
    "ironed_testX = iron_scaler.transform(data_test[train_features]).values.astype('float32')\n",
    "\n",
    "trainY = data_train.Signal.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "st_scaler = StandardScaler()\n",
    "st_scaler.fit(data_train[train_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single layer with StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_1layer_model(input_dim, hidden_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_dim, input_dim=input_dim))\n",
    "    model.add(Activation('tanh'))\n",
    "\n",
    "    n_classes = len(set(trainY))\n",
    "    model.add(Dense(n_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keras_no_iron_clf = prepare_1layer_model(input_dim=len(train_features), hidden_dim=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('log_nn_base', 'w') as f:\n",
    "    f.write(\"Simple NN, standard scaler\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): We did not found a dynamic library into the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4h 28min 31s, sys: 12h 32min 45s, total: 17h 1min 16s\n",
      "Wall time: 2h 33min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for epochs in range(15):\n",
    "    keras_no_iron_clf.fit(st_scaler.transform(data_train[train_features]), np_utils.to_categorical(trainY), \n",
    "                          verbose=0, nb_epoch=5, batch_size=256)\n",
    "    p = keras_no_iron_clf.predict_proba(st_scaler.transform(data_test[train_features]), verbose=False)\n",
    "    auc = roc_auc_score_one_vs_all(data_test.Signal, p, data_test.Weight).values\n",
    "    with open('log_nn_base', 'a') as f:\n",
    "        f.write(\"{}\\n\".format(auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keras_onelayer_clf = prepare_1layer_model(input_dim=len(train_features), hidden_dim=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('log_nn_base', 'a') as f:\n",
    "    f.write(\"Simple NN, iron scaler\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3h 3min 35s, sys: 7h 43min 11s, total: 10h 46min 47s\n",
      "Wall time: 1h 37min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epochs in range(15):\n",
    "    keras_onelayer_clf.fit(ironed_trainX, np_utils.to_categorical(trainY), \n",
    "                           verbose=0, nb_epoch=5, batch_size=256)\n",
    "    p = keras_onelayer_clf.predict_proba(ironed_testX, verbose=False)\n",
    "    auc = roc_auc_score_one_vs_all(data_test.Signal, p, data_test.Weight).values\n",
    "    with open('log_nn_base', 'a') as f:\n",
    "        f.write(\"{}\\n\".format(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_predictions(keras_onelayer_clf.predict_proba(iron_scaler.transform(data_test_full[train_features]).values, verbose=False),\n",
    "                 filename='./models/keras_onelayer_probs.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepare_deep_model(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(300, input_dim=input_dim))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(300))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(400))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    n_classes = len(set(trainY))\n",
    "\n",
    "    model.add(Dense(n_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keras_dl_clf = prepare_deep_model(len(train_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('log_nn_base', 'a') as f:\n",
    "    f.write(\"Deep learning\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for epochs in range(5):\n",
    "    keras_dl_clf.fit(ironed_trainX, np_utils.to_categorical(trainY), \n",
    "                     verbose=0, nb_epoch=10, batch_size=256)\n",
    "\n",
    "    p = keras_dl_clf.predict_proba(ironed_testX, verbose=False)\n",
    "    val = roc_auc_score_one_vs_all(data_test.Signal, p, data_test.Weight).values\n",
    "    with open('log_nn_base', 'a') as f:\n",
    "        f.write('{}\\n'.format(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_predictions(keras_dl_clf.predict_proba(iron_scaler.transform(data_test_full[train_features]).values, verbose=False),\n",
    "                 filename='./models/keras_dl_probs.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### + pv features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hep_ml.preprocessing import IronTransformer\n",
    "\n",
    "iron_scaler_pv = IronTransformer(symmetrize=True)\n",
    "iron_scaler_pv.fit(data_train[train_features + pv_features])\n",
    "\n",
    "ironed_trainX_pv = iron_scaler.transform(data_train[train_features + pv_features]).values.astype('float32')\n",
    "ironed_testX_pv = iron_scaler.transform(data_test[train_features + pv_features]).values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keras_dl_clf_pv = prepare_deep_model(len(train_features) + len(pv_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('log_nn_pv', 'w') as f:\n",
    "    f.write('Deep nn, + pv\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for epochs in range(5):\n",
    "    keras_dl_clf_pv.fit(ironed_trainX_pv, np_utils.to_categorical(trainY), \n",
    "                     verbose=0, nb_epoch=10, batch_size=256)\n",
    "\n",
    "    p = keras_dl_clf_pv.predict_proba(ironed_testX_pv, verbose=False)\n",
    "    val = roc_auc_score_one_vs_all(data_test.Signal, p, data_test.Weight).values\n",
    "    with open('log_nn_pv', 'a') as f:\n",
    "        f.write('{}\\n'.format(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_predictions(keras_dl_clf_pv.predict_proba(iron_scaler.transform(data_test_full[train_features + pv_features]).values,\n",
    "                                               verbose=False),\n",
    "                 filename='./models/keras_dl_probs_pv.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras with sublayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Layer\n",
    "from keras import backend as K\n",
    "\n",
    "class SublayersLayer(Layer):\n",
    "    def __init__(self, sizes, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        self.sizes = sizes\n",
    "        super(SublayersLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_dim = input_shape[1]\n",
    "        self.trainable_weights = []\n",
    "        for i in range(len(self.sizes) - 1):\n",
    "            matrix_size = (self.sizes[i+1] - self.sizes[i], self.output_dim)\n",
    "            initial_weight_value = numpy.random.random(size=matrix_size)\n",
    "            W = K.variable(initial_weight_value)\n",
    "            self.trainable_weights.append(W)\n",
    "            # print matrix_size\n",
    "        self.trainable_weights.append(K.zeros((self.output_dim * (len(self.sizes) - 1),)))\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        sublayers_outputs = []\n",
    "        assert len(self.trainable_weights) == (len(self.sizes) - 1) + 1\n",
    "        for i in range(len(self.sizes) - 1):\n",
    "            w = self.trainable_weights[i]\n",
    "            sublayers_outputs.append(K.dot(x[:, self.sizes[i]:self.sizes[i+1]], w))\n",
    "   \n",
    "        return K.concatenate(sublayers_outputs, axis=1) + self.trainable_weights[-1]\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim * (len(self.sizes) - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from theano import tensor\n",
    "from keras.layers import InputLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepare_sublayers(input_dim, feature_families):\n",
    "    model = Sequential()\n",
    "    model.add(Activation('linear', input_shape=[input_dim]))\n",
    "\n",
    "    sublayer_sizes = numpy.cumsum([0] + map(len, feature_families.values()))\n",
    "    print sublayer_sizes\n",
    "    model.add(SublayersLayer(sizes=sublayer_sizes, output_dim=50))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(300))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(400))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    n_classes = len(set(trainY))\n",
    "\n",
    "    model.add(Dense(n_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keras_sublayers_clf = prepare_sublayers(len(train_features), feature_families=feature_families)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('log_nn_base', 'a') as f:\n",
    "    f.write(\"Sublayers\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for epochs in range(5):\n",
    "    keras_sublayers_clf.fit(ironed_trainX, np_utils.to_categorical(trainY), \n",
    "                     verbose=0, nb_epoch=10, batch_size=256)\n",
    "\n",
    "    p = keras_sublayers_clf.predict_proba(ironed_testX, verbose=False)\n",
    "    sublayers_auc = roc_auc_score_one_vs_all(data_test.Signal, p, data_test.Weight).values\n",
    "    with open('log_nn_base', 'a') as f:\n",
    "        f.write('{}\\n'.format(sublayers_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_predictions(keras_sublayers_clf.predict_proba(iron_scaler.transform(data_test_full[train_features]).values, verbose=False),\n",
    "                 filename='./models/keras_sublayers_probs.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras for staged training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_small_model(input_dim, hidden_layer):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_layer, input_dim=input_dim))\n",
    "    # added dropout in order not to care about folding :)\n",
    "    model.add(Dropout(p=0.3))\n",
    "    model.add(Activation('tanh'))\n",
    "\n",
    "    n_classes = len(set(trainY))\n",
    "    model.add(Dense(n_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    keras_onelayer_clf = model\n",
    "    keras_onelayer_clf.compile(loss='categorical_crossentropy', optimizer=Adam())\n",
    "    return keras_onelayer_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('log_nn_base', 'a') as f:\n",
    "    f.write(\"Stacking\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "family_models = {}\n",
    "for family_name, family_features in feature_families.items():\n",
    "    family_model = generate_small_model(len(family_features), hidden_layer=50)\n",
    "    family_models[family_name] = family_model\n",
    "    family_model.fit(pandas.DataFrame(ironed_trainX, columns=train_features)[family_features].values, \n",
    "                     np_utils.to_categorical(trainY), \n",
    "                     verbose=0, nb_epoch=20, batch_size=256)\n",
    "    print 'done'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for family_name, family_features in feature_families.items():\n",
    "    family_model = family_models[family_name]\n",
    "    test_pred = family_model.predict_proba(pandas.DataFrame(ironed_testX, columns=train_features)[family_features].values, verbose=False)\n",
    "    print roc_auc_score_one_vs_all(data_test.Signal, test_pred, data_test.Weight).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def collect_features(data):\n",
    "    ironed_data = iron_scaler.transform(data[train_features])\n",
    "    joint_data = [ironed_data]\n",
    "    for family_name, family_features in feature_families.items():\n",
    "        family_model = family_models[family_name]\n",
    "        pred = family_model.predict_proba(ironed_data[family_features].values, verbose=False)\n",
    "        joint_data.append(pandas.DataFrame(pred))\n",
    "    return pandas.concat(joint_data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_full = collect_features(data_train)\n",
    "test_full = collect_features(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepare_combiner_model(input_dim):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(300, input_dim=input_dim))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(400))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    n_classes = len(set(trainY))\n",
    "\n",
    "    model.add(Dense(n_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keras_combiner_clf = prepare_combiner_model(train_full.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "for epochs in range(5):\n",
    "    keras_combiner_clf.fit(train_full.values, np_utils.to_categorical(trainY), verbose=0, nb_epoch=5, batch_size=256)\n",
    "    p = keras_combiner_clf.predict_proba(test_full.values, verbose=False)\n",
    "    print roc_auc_score_one_vs_all(data_test.Signal, p, data_test.Weight).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_predictions(keras_combiner_clf.predict_proba(collect_features(data_test_full).values, verbose=False),\n",
    "                 filename='./models/keras_subdetectors_probs.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
