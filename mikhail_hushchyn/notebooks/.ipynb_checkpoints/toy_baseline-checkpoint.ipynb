{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "These is a base solution of PID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import root_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {}\n",
    "\n",
    "# Nets to track\n",
    "params['TRACK'] = \"Downstream\" # \"Long Downstream Upstream\"\n",
    "params['PARTICLE'] = \"Electron\" # \"Electron Muon Pion Kaon Proton Ghost\"\n",
    "\n",
    "\n",
    "# General parameters\n",
    "params['GHOSTACPTFRAC'] = 1.0\n",
    "params['REUSETRAININGFILES'] = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Classifier\n",
    "params['MVATYPE'] = \"TMVA\"\n",
    "\n",
    "# General Neural Network Options\n",
    "params['MLPHIDDENLAYERSCALEF'] = 1.4\n",
    "# TMVA Defaults\n",
    "params['TMVAMETHOD'] = \"MLP\"\n",
    "params['TMVAUSEREGULATOR'] = \"true\"\n",
    "# MLP\n",
    "params['TMVAMLPNCYCLES'] = \"50\" #!!!! 750\n",
    "params['TMVAMLPNEURONTYPE'] = \"sigmoid\"\n",
    "params['TMVAMLPMETHOD'] = \"BP\"\n",
    "params['TMVAMLPESTIMATORTYPE'] = \"CE\"\n",
    "params['TMVAMLPCONVIMPROVE'] = \"1e-16\"\n",
    "params['TMVAMLPCONVTEST'] = \"15\"\n",
    "# BDT\n",
    "params['TMVABDTBOOSTTYPE'] = \"AdaBoost\"\n",
    "params['TMVABDTNTREES'] = \"800\"\n",
    "params['TMVAVARTRANSFORM'] = \"Norm\"\n",
    "params['TMVABDTPRUNEMETHOD'] = \"CostComplexity\"\n",
    "params['TMVABDTMAXTREEDEPTH'] = \"3\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Overall root dir\n",
    "params['MAINROOT'] = \"\"\n",
    "# Config directory\n",
    "params['CONFIGDIR'] = params['MAINROOT'] + \"configs\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Network config\n",
    "params['CONFIGNAME'] = \"NoPreSels-NumSPDR1R2\"\n",
    "params['NNCONFIGNAME'] = params['MVATYPE'] + \"-\" + params['CONFIGNAME']\n",
    "params['NNCONFIGDIR'] = params['CONFIGDIR'] + \"/networks/\" + params['NNCONFIGNAME']\n",
    "params['NETCONFIG'] = params['NNCONFIGDIR'] + \"/\" + \\\n",
    "                      \"GlobalPID_\" + params['PARTICLE'] + \"_\" + params['TRACK'] + \"_ANN.txt\"\n",
    "    \n",
    "# Training config\n",
    "params['TRAINCONFIGNAME'] = \"test\"\n",
    "params['TRAINCONFIGDIR'] = params['CONFIGDIR'] + \"/training/\"\n",
    "params['TRAINCONFIG'] = params['TRAINCONFIGDIR'] + \\\n",
    "                        params['MVATYPE'] + \"-\" + params['TRAINCONFIGNAME'] + \".txt\"\n",
    "    \n",
    "# MVA Configuration\n",
    "params['MVACONFIG'] = params['TRAINCONFIGDIR'] + \"/MVA-Configuration.txt\"\n",
    "params['TMVAVALIDATIONFRAC'] = '0.3'\n",
    "params['TMVATESTFRAC'] = '0.3'\n",
    "\n",
    "# Preselection configs\n",
    "params['TRACKSELCONFIGDIR'] = params['CONFIGDIR'] + \"/TrackSelection/\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Training data\n",
    "params['DATAFILES'] = \"MC12\"\n",
    "params['TRAININGDATA'] = \"Mixture\"\n",
    "params['TRAINFILES'] = params['TRAINCONFIGDIR'] + \"/\" + params['DATAFILES'] + \"-TrainingFiles-\" + \\\n",
    "                       params['TRAININGDATA'] + \"-Cambridge.txt\"\n",
    "    \n",
    "    \n",
    "# Eval data\n",
    "params['EVALDATA'] = \"Mixture\"\n",
    "params['EVALFILES'] = params['TRAINCONFIGDIR'] + \"/\" + params['DATAFILES'] + \"-TrainingFiles-\" + \\\n",
    "                      params['EVALDATA'] + \"-Cambridge.txt\"\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "# Other train parameters   \n",
    "params['EVALPARAMSFILE'] = \"None\"\n",
    "params['DOTRAIN'] = \"Yes\"\n",
    "params['DOEVAL'] = \"No\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Main training directory\n",
    "params['TRAINLOC']=params['DATAFILES'] + \"/Train\" + params['TRAININGDATA'] + \"/\" + params['TRAINCONFIGNAME'] + \\\n",
    "                   \"/GhostAccFrac\" + str(params['GHOSTACPTFRAC']) + \"/\" + params['NNCONFIGNAME']\n",
    "    \n",
    "if params['TMVAMETHOD'] == \"MLP\":\n",
    "    params['TRAINLOC'] = params['TRAINLOC'] + \"/\" + params['TMVAMETHOD'] + \"/\" + params['TMVAVARTRANSFORM'] + \\\n",
    "    \"/ScaleF\" + str(params['MLPHIDDENLAYERSCALEF']) + \"/\" + params['TMVAMLPMETHOD'] + \"/NCycles\" + \\\n",
    "    params['TMVAMLPNCYCLES'] + \"/\" + params['TMVAMLPESTIMATORTYPE'] + \"/\" + params['TMVAMLPNEURONTYPE'] + \\\n",
    "    \"/CVTest\" + params['TMVAMLPCONVTEST'] + \"/CVImp\" + params['TMVAMLPCONVIMPROVE']\n",
    "else:\n",
    "    params['TRAINLOC'] = params['TRAINLOC'] + \"/\" + params['TMVAMETHOD'] + \"/\" + params['TMVAVARTRANSFORM'] + \\\n",
    "    \"/\" + params['TMVABDTBOOSTTYPE'] + \"/NTrees\" + params['TMVABDTNTREES'] + \"/MaxDepth\" + \\\n",
    "    params['TMVABDTMAXTREEDEPTH'] + \"/\" + params['TMVABDTPRUNEMETHOD']\n",
    "\n",
    "if params['TMVAUSEREGULATOR'] == \"true\":\n",
    "    params['TRAINLOC'] = params['TRAINLOC'] + \"/UseRegulator\"\n",
    "else:\n",
    "    params['TRAINLOC'] = params['TRAINLOC'] + \"/NotUseRegulator\"\n",
    "\n",
    "params['TRAINDIR'] = params['MAINROOT'] + \"results/\" + params['TRAINLOC']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import os, sys\n",
    "# sys.path.append('src')\n",
    "# from teacher import teacher\n",
    "# tmva, data_train_signal, data_train_bkg, data_test_signal, data_test_bkg = teacher(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_pid_type = 999999\n",
    "particle_pdg_codes = {\"all\": all_pid_type, \n",
    "                    \"ghost\": 0, \n",
    "                    \"electron\": 11, \n",
    "                    \"muon\": 13, \n",
    "                    \"pion\": 211, \n",
    "                    \"kaon\": 321, \n",
    "                    \"proton\": 2212}\n",
    "\n",
    "comb_dlls = {\"electron\": \"CombDLLe\", \n",
    "             \"muon\": \"CombDLLmu\", \n",
    "             \"pion\": \"CombDLLpi\", \n",
    "             \"kaon\": \"CombDLLk\", \n",
    "             \"proton\": \"CombDLLp\", \n",
    "             \"ghost\": \"TrackGhostProbability\"}\n",
    "\n",
    "track_selections = {\"Long\": \"abs(TrackType-3) < 0.1\",\n",
    "                    \"Upstream\": \"abs(TrackType-4) < 0.1\",\n",
    "                     \"Downstream\": \"abs(TrackType-5) < 0.1\"}\n",
    "\n",
    "GeV = 1000\n",
    "limits = {\"TrackP\": [100*GeV, 0],\n",
    "          \"TrackPt\": [10*GeV, 0],\n",
    "          \"CombDLLe\": [20, -20],\n",
    "          \"CombDLLmu\": [20, -20],\n",
    "          \"CombDLLpi\": [150, -150],\n",
    "          \"CombDLLk\": [150, -150],\n",
    "          \"CombDLLp\": [150, -150] }\n",
    "\n",
    "mass_hypos = [11,13,211,321,2212,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createRICH2HitsReweightSel():\n",
    "\n",
    "    selS = \"( 0.00108528 +\" + \\\n",
    "           \"( -1.0822e-05  * NumRich2Hits        ) +\" + \\\n",
    "           \"( 3.51537e-08  * pow(NumRich2Hits,2) ) +\" + \\\n",
    "           \"( -4.6664e-11  * pow(NumRich2Hits,3) ) +\" + \\\n",
    "           \"( 3.16421e-14  * pow(NumRich2Hits,4) ) +\" + \\\n",
    "           \"( -8.69538e-18 * pow(NumRich2Hits,5) ) +\" + \\\n",
    "           \"( 1.14595e-21  * pow(NumRich2Hits,6) ) )\" + \\\n",
    "           \" > rndm\"\n",
    "\n",
    "    return selS\n",
    "\n",
    "def get_params(params, key_val, default):\n",
    "    \n",
    "    if params.has_key(key_val):\n",
    "        param_val = params[key_val]\n",
    "    else:\n",
    "        param_val = default\n",
    "        \n",
    "    return param_val\n",
    "\n",
    "\n",
    "def get_overal_track_sel(track_type_sel, track_sel, mc_track_sel_training):\n",
    "    \n",
    "    overall_training_sel = \"\"\n",
    "    \n",
    "    # add track_type_sel\n",
    "    for sel in [track_type_sel]:\n",
    "        \n",
    "        if overall_training_sel == \"\":\n",
    "            overall_training_sel += \" ( \" + sel + \" ) \"\n",
    "            \n",
    "        else:\n",
    "            overall_training_sel += \" && \" + \" ( \" + sel + \" ) \" \n",
    "            \n",
    "    # add track_sel\n",
    "    for sel in track_sel:\n",
    "        \n",
    "        if overall_training_sel == \"\":\n",
    "            overall_training_sel += \" ( \" + sel + \" ) \"\n",
    "            \n",
    "        else:\n",
    "            overall_training_sel += \" && \" + \" ( \" + sel + \" ) \" \n",
    "            \n",
    "    # add mc_track_sel_training\n",
    "    for sel in mc_track_sel_training:\n",
    "        \n",
    "        if overall_training_sel == \"\":\n",
    "            overall_training_sel += \" ( \" + sel + \" ) \"\n",
    "            \n",
    "        else:\n",
    "            overall_training_sel += \" && \" + \" ( \" + sel + \" ) \" \n",
    "    \n",
    "    return overall_training_sel\n",
    "\n",
    "\n",
    "def create_ghost_accept_sel(ghost_accept_frac):\n",
    "    sel = \"\"\n",
    "    if ghost_accept_frac < 1.0 :\n",
    "        sel = \"( MCParticleType != 0 || rndm < \" + str(ghost_accept_frac) + \" )\"\n",
    "    return sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###################################################\n",
    "# Initialise\n",
    "###################################################\n",
    "\n",
    "# Running options\n",
    "do_train = params['DOTRAIN']\n",
    "do_eval = params['DOEVAL']\n",
    "\n",
    "# Open network config file\n",
    "net_config = numpy.loadtxt(params['NETCONFIG'], dtype='S', delimiter='\\n', comments='!')\n",
    "\n",
    "# Open training config file\n",
    "train_config = numpy.loadtxt(params['TRAINCONFIG'], dtype='S', delimiter='\\n', comments='#')\n",
    "\n",
    "# Open MVA specific config file\n",
    "mva_config = numpy.loadtxt(params['MVACONFIG'], dtype='S', delimiter='\\n', comments='#')\n",
    "\n",
    "# Open eval config file\n",
    "eval_params = \"None\"\n",
    "if params['EVALPARAMSFILE'] != \"None\":\n",
    "    eval_params = numpy.loadtxt(params['EVALPARAMSFILE'], dtype='S', delimiter='\\n', comments='#')\n",
    "    \n",
    "# Training data files\n",
    "train_files = numpy.loadtxt(params['TRAINFILES'], dtype='S', delimiter='\\n', comments='#')\n",
    "\n",
    "# Eval data files\n",
    "eval_files = numpy.loadtxt(params['EVALFILES'], dtype='S', delimiter='\\n', comments='#')\n",
    "\n",
    "# Read the particle type\n",
    "particle_type = net_config[0]\n",
    "particle_pdg = particle_pdg_codes[particle_type]\n",
    "particle_comb_dll = comb_dlls[particle_type]\n",
    "\n",
    "# Read the track type\n",
    "track_type = net_config[1]\n",
    "track_type_sel = track_selections[track_type]\n",
    "\n",
    "# Track selection file\n",
    "track_sel_file = params['TRACKSELCONFIGDIR'] + net_config[2]\n",
    "\n",
    "# Background type\n",
    "bkg_type = train_config[0]\n",
    "bkg_pdg = particle_pdg_codes[bkg_type]\n",
    "\n",
    "# Ghost treatment for training\n",
    "ghost_treatment_training = train_config[1]\n",
    "keep_ghost_training = train_config[1] != \"NoGhosts\"\n",
    "\n",
    "# Ghost treatment for evaluation\n",
    "ghost_treatment_eval = train_config[2]\n",
    "keep_ghost_eval = train_config[2] != \"NoGhosts\"\n",
    "\n",
    "# MC track training selection\n",
    "mc_track_sel_training_name = train_config[3]\n",
    "mc_track_sel_training_file = params['TRAINCONFIGDIR'] + train_config[3]\n",
    "\n",
    "# MC track eval selection\n",
    "mc_track_sel_eval_file = train_config[4]\n",
    "\n",
    "# Signal/Background mix\n",
    "training_mix = train_config[5]\n",
    "\n",
    "# Reweighting\n",
    "reweight_opt = train_config[6]\n",
    "\n",
    "# Read the network type\n",
    "mva_type = net_config[3]\n",
    "\n",
    "# Read network parameters file name\n",
    "param_file_name = net_config[4]\n",
    "\n",
    "\n",
    "# Read train and spectator features\n",
    "features = []\n",
    "spectator_features = []\n",
    "\n",
    "for var in net_config[5:]:\n",
    "    if var.find('#') == -1:\n",
    "        features.append(var)\n",
    "    else:\n",
    "        spectator_features.append(var[1:])\n",
    "        \n",
    "# Tracks type selection ???\n",
    "track_type_sel = track_selections[track_type]\n",
    "\n",
    "# Tracks preselection\n",
    "track_sel = numpy.loadtxt(track_sel_file, dtype='S', delimiter='\\n', comments='#')\n",
    "\n",
    "# MC tracks training selectiom\n",
    "mc_track_sel_training = numpy.loadtxt(mc_track_sel_training_file, dtype='S', delimiter='\\n', comments='#')\n",
    "\n",
    "# Reweighting selection\n",
    "if reweight_opt == \"ReweightRICH2\" :\n",
    "    reweight_sel = createRICH2HitsReweightSel()\n",
    "else:\n",
    "    reweight_sel = \"\"\n",
    "    \n",
    "# Number of training tracks\n",
    "n_training_tracks = train_config[7]\n",
    "\n",
    "# Number of eval tracks\n",
    "n_eval_tracks = train_config[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###############################################\n",
    "# Configure the teacher\n",
    "###############################################\n",
    "\n",
    "# Number of inputs and hidden nodes\n",
    "if params.has_key('MLPHIDDENLAYERSCALEF'):\n",
    "    layer_two_scale = params['MLPHIDDENLAYERSCALEF']\n",
    "else:\n",
    "    layer_two_scale = 1.2\n",
    "    \n",
    "n_var = len(features)\n",
    "\n",
    "n_hidden_nodes = int(n_var * layer_two_scale)\n",
    "\n",
    "\n",
    "# Ghost accept fraction\n",
    "ghost_accept_frac = get_params(params, 'GHOSTACPTFRAC', 1.0)\n",
    "    \n",
    "if ghost_accept_frac < 1.0 and \"EqualMix\" == training_mix:\n",
    "    print \"Ghost Fraction < 1 makes no sense with equal mixture training\"\n",
    "\n",
    "\n",
    "# Evaluation data files\n",
    "eval_set = get_params(params, 'EVALDATA', \"Mixture\")\n",
    "    \n",
    "\n",
    "# Reuse files for eval\n",
    "reuse_files = get_params(params, 'REUSETRAININGFILES', 0)\n",
    "    \n",
    "    \n",
    "# TMVA parameters\n",
    "# General\n",
    "tmva_method = get_params(params, \"TMVAMETHOD\",\"MLP\")\n",
    "tmva_var_transform = get_params(params,\"TMVAVARTRANSFORM\",\"None\")\n",
    "tmva_validation_frac = get_params(params, \"TMVAVALIDATIONFRAC\",0.3)\n",
    "tmva_test_frac = get_params(params, \"TMVATESTFRAC\",0.3)\n",
    "tmva_use_regulator = get_params(params, \"TMVAUSEREGULATOR\",\"false\")\n",
    "# MLP specific\n",
    "tmva_mlp_neuron_type = get_params(params, \"TMVAMLPNEURONTYPE\",\"sigmoid\")\n",
    "tmva_mlp_method = get_params(params, \"TMVAMLPMETHOD\",\"BP\")\n",
    "tmva_mlp_n_cycles = get_params(params, \"TMVAMLPNCYCLES\",\"500\")\n",
    "tmva_mlp_estimator_type = get_params(params, \"TMVAMLPESTIMATORTYPE\",\"CE\")\n",
    "tmva_mlp_conv_improve = get_params(params, \"TMVAMLPCONVIMPROVE\",\"1e-16\")\n",
    "tmva_mlp_conv_test = get_params(params, \"TMVAMLPCONVTEST\",-1)\n",
    "# BDT specific\n",
    "tmva_bdt_boost_type = get_params(params, \"TMVABDTBOOSTTYPE\",\"AdaBoost\")\n",
    "tmva_bdt_n_trees = get_params(params, \"TMVABDTNTREES\",\"800\")\n",
    "tmva_bdt_prune_method = get_params(params, \"TMVABDTPRUNEMETHOD\",\"NoPruning\")\n",
    "tmva_bdt_max_tree_depth = get_params(params, \"TMVABDTMAXTREEDEPTH\",\"3\")\n",
    "\n",
    "\n",
    "# Sanity checks\n",
    "if particle_type == bkg_type:\n",
    "    print \"Background and PID types the same \" + particleType + \" !!!\"\n",
    "    \n",
    "if \"Ghost\" == particle_type and\\\n",
    "  (\"NoGhosts\" == ghost_treatment_training or\\\n",
    "   \"NoGhosts\" == ghost_treatment_eval or\\\n",
    "   \"BTracksOnly.txt\" == mc_track_sel_training_name or\\\n",
    "    ghost_accept_frac <= 0.0):\n",
    "        \n",
    "    print \"Cannot train ghost ID network whilst rejecting ghosts !!!\"\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "# Read in training data\n",
    "#############################################\n",
    "\n",
    "# Count tracks overall\n",
    "all_tracks = 0\n",
    "selected_tracks = 0\n",
    "signal_tracks = 0\n",
    "background_tracks = 0\n",
    "test_tracks = 0\n",
    "\n",
    "selected_tracks_by_type = {11: 0, 13: 0, 211: 0, 321: 0, 2212: 0, 0: 0}\n",
    "\n",
    "\n",
    "# Overall selection\n",
    "overall_training_sel = get_overal_track_sel(track_type_sel, track_sel, mc_track_sel_training)\n",
    "\n",
    "# Full selection for file determination\n",
    "if reweight_sel != \"\":\n",
    "    train_data_file_sel = overall_training_sel + \" && \" + \" ( \" +  reweight_sel + \" ) \"\n",
    "else:\n",
    "    train_data_file_sel = overall_training_sel\n",
    "\n",
    "# Ghost selection\n",
    "ghost_accept_sel = create_ghost_accept_sel(ghost_accept_frac)\n",
    "\n",
    "# Combined train selection\n",
    "if ghost_accept_sel != \"\":\n",
    "    combined_train_sel = train_data_file_sel + \" && (\" + ghost_accept_sel + \" )\"\n",
    "else :\n",
    "    combined_train_sel = train_data_file_sel\n",
    "\n",
    "# Do we want equal amounts of all particle types ?\n",
    "equal_by_type = ( \"EqualMix\" == training_mix )\n",
    "if ghost_accept_frac > 0.0 and keep_ghost_training:\n",
    "    n_hypos = 1. * len(mass_hypos)\n",
    "else:\n",
    "    n_hypos = 1. * len(mass_hypos) - 1.\n",
    "n_per_type = 1 + ( float(n_training_tracks) / n_hypos )\n",
    "\n",
    "\n",
    "# Data Frames for trainer\n",
    "data_train_signal = pandas.DataFrame()\n",
    "data_train_bkg = pandas.DataFrame()\n",
    "data_test_signal = pandas.DataFrame()\n",
    "data_test_bkg = pandas.DataFrame()\n",
    "\n",
    "\n",
    "# Loop over training file list as far as required\n",
    "n_files_used = 0\n",
    "\n",
    "for data_file in [train_files[0], train_files[1]]: #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    \n",
    "    n_files_used += 1\n",
    "    \n",
    "    # Get data file path and tree name\n",
    "    data_file_path, data_file_tree = data_file.split(':')\n",
    "    \n",
    "    # Open data file and convert it to csv\n",
    "    branches = root_numpy.list_branches(data_file_path, treename=data_file_tree)\n",
    "    branches = numpy.array(branches)\n",
    "    \n",
    "    training_tree = root_numpy.root2array(data_file_path, \n",
    "                                          treename=data_file_tree, \n",
    "                                          branches=branches[branches != 'piplus_OWNPV_COV_'],\n",
    "                                          selection = combined_train_sel)\n",
    "\n",
    "    training_tree = pandas.DataFrame(data=training_tree, columns=branches[branches != 'piplus_OWNPV_COV_'])\n",
    "    \n",
    "    # MC type\n",
    "    mc_particle_type = training_tree.MCParticleType.values\n",
    "    \n",
    "    # Count selected tracks for this file\n",
    "    selected_tracks_file = 0\n",
    "    test_tracks_file = 0\n",
    "    \n",
    "    # Loop over entry list\n",
    "    for irow in range(0, len(training_tree)):\n",
    "        \n",
    "        data_row = training_tree.irow([irow])\n",
    "        \n",
    "        mc_particle_type = numpy.abs(data_row.MCParticleType.values[0])\n",
    "        \n",
    "        # Count all tracks considered\n",
    "        all_tracks += 1\n",
    "    \n",
    "        # Ghost treatment\n",
    "        if 0 == mc_particle_type and not keep_ghost_training:\n",
    "            continue\n",
    "        \n",
    "        # True or fake target\n",
    "        target = mc_particle_type == particle_pdg\n",
    "    \n",
    "        # Equal mix ?            \n",
    "        if (equal_by_type and selected_tracks_by_type[mc_particle_type] >= n_per_type) or \\\n",
    "            not selected_tracks_by_type.has_key(mc_particle_type) :\n",
    "            continue\n",
    "            \n",
    "        # Background type selection for training\n",
    "        if not ( target or all_pid_type == bkg_pdg or mc_particle_type == int(bkg_pdg) ):\n",
    "            continue\n",
    "            \n",
    "        # Count signal and background\n",
    "        if target:\n",
    "            signal_tracks += 1\n",
    "        else:\n",
    "            background_tracks += 1\n",
    "            \n",
    "        # Fill an input array for the teacher ?????\n",
    "        \n",
    "        # Make sure min and max are filled for spectators ?????\n",
    "        \n",
    "        use_for_testing = \"False\"\n",
    "        \n",
    "        # Set inputs and target output\n",
    "        use_for_testing = numpy.random.rand() < float(tmva_test_frac)\n",
    "        \n",
    "        if target:\n",
    "            \n",
    "            if not use_for_testing:\n",
    "                data_train_signal = pandas.concat([data_train_signal, data_row[features]], ignore_index=True)\n",
    "            else:\n",
    "                data_test_signal = pandas.concat([data_test_signal, data_row[features]], ignore_index=True)\n",
    "               \n",
    "        else:\n",
    "            \n",
    "            if not use_for_testing:\n",
    "                data_train_bkg = pandas.concat([data_train_bkg, data_row[features]], ignore_index=True)\n",
    "            else:\n",
    "                data_test_bkg = pandas.concat([data_test_bkg, data_row[features]], ignore_index=True)\n",
    "                \n",
    "        \n",
    "        # count tracks\n",
    "        if not use_for_testing:\n",
    "            selected_tracks += 1\n",
    "            selected_tracks_file += 1;\n",
    "            selected_tracks_by_type[mc_particle_type] += 1\n",
    "        else:\n",
    "            test_tracks += 1\n",
    "            test_tracks_file += 1\n",
    "            \n",
    "        # Found enough tracks ?\n",
    "        if selected_tracks >= int(n_training_tracks):\n",
    "            break\n",
    "       \n",
    "    \n",
    "    \n",
    "    # Found enough tracks ?\n",
    "    if selected_tracks >= n_training_tracks:\n",
    "        break\n",
    "        \n",
    "    # Used 1/2 of the training files ?\n",
    "    if n_files_used > len(train_files)/2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from rep.estimators import TMVAClassifier\n",
    "\n",
    "##############################################\n",
    "# For TMVA, must setup the method here\n",
    "##############################################\n",
    "\n",
    "if params['MVATYPE'] == 'TMVA':\n",
    "    \n",
    "    # Prepare the data\n",
    "    config = \"V:nTrain_Signal=0:nTrain_Background=0:SplitMode=Random\"\n",
    "    if \"EqualSigBck\" == training_mix:\n",
    "        config += \":NormMode=EqualNumEvents\"\n",
    "    else:\n",
    "        config += \":NormMode=None\"\n",
    "    # tmvaFactory->PrepareTrainingAndTestTree( cuts, config.c_str() ) !!!!!!!!\n",
    "    \n",
    "    \n",
    "    # TMVA Method name\n",
    "    name = particle_type + \"_\" + track_type + \"_TMVA\"\n",
    "    \n",
    "    # Sort of TMVA classifier\n",
    "    if \"MLP\" == tmva_method:\n",
    "        \n",
    "        # Construct MLP options\n",
    "        tmva = TMVAClassifier(method='kMLP', \n",
    "                              features=features,\n",
    "                              factory_options=\"V:!Silent:!Color:!DrawProgressBar\",\n",
    "                              H='true', \n",
    "                              V='true', \n",
    "                              EpochMonitoring='true', \n",
    "                              HiddenLayers=str(n_hidden_nodes), \n",
    "                              UseRegulator=tmva_use_regulator)\n",
    "        \n",
    "        if int(tmva_mlp_conv_test) > 0:\n",
    "            tmva.set_params(ConvergenceImprove = tmva_mlp_conv_improve)\n",
    "            tmva.set_params(ConvergenceTests = tmva_mlp_conv_test)\n",
    "        if \"DEFAULT\" != tmva_var_transform:\n",
    "            tmva.set_params(VarTransform = tmva_var_transform)\n",
    "        if \"DEFAULT\" != tmva_mlp_n_cycles:\n",
    "            tmva.set_params(NCycles = tmva_mlp_n_cycles)\n",
    "        if \"DEFAULT\" != tmva_mlp_neuron_type:\n",
    "            tmva.set_params(NeuronType = tmva_mlp_neuron_type)\n",
    "        if \"DEFAULT\" != tmva_mlp_method:\n",
    "            tmva.set_params(TrainingMethod = tmva_mlp_method)\n",
    "        if \"DEFAULT\" != tmva_mlp_estimator_type:\n",
    "            tmva.set_params(EstimatorType = tmva_mlp_estimator_type)\n",
    "        # tmvaFactory->BookMethod( TMVA::Types::kMLP, name.str().c_str(), opts.str().c_str() );\n",
    "        \n",
    "    elif \"BDT\" == tmva_method:\n",
    "        \n",
    "        # BDT opts\n",
    "        tmva = TMVAClassifier(method='kBDT', \n",
    "                              features=features,\n",
    "                              factory_options=\"V:!Silent:!Color:!DrawProgressBar\",\n",
    "                              H='false', \n",
    "                              V='true', \n",
    "                              NTrees=tmva_bdt_n_trees)\n",
    "        \n",
    "        # opts += \":UseRegulator=\" + tmva_use_regulator\n",
    "        if \"DEFAULT\" != tmva_var_transform:\n",
    "            tmva.set_params(VarTransform = tmva_var_transform)\n",
    "        if \"DEFAULT\" != tmva_bdt_boost_type:\n",
    "            tmva.set_params(BoostType = tmva_bdt_boost_type)\n",
    "        if \"DEFAULT\" != tmva_bdt_prune_method:\n",
    "            tmva.set_params(PruneMethod = tmva_bdt_prune_method)\n",
    "        if \"CostComplexity\" == tmva_bdt_prune_method or \"ExpectedError\" == tmva_bdt_prune_method:\n",
    "            tmva.set_params(PruneStrength = -1)\n",
    "        if \"DEFAULT\" != tmva_bdt_max_tree_depth:\n",
    "            tmva.set_params(MaxDepth = tmva_bdt_max_tree_depth)\n",
    "        if float(tmva_validation_frac) > 0 and \"NoPruning\" != tmva_bdt_prune_method:\n",
    "            tmva.set_params(PruningValFraction = tmva_validation_frac)\n",
    "        # tmvaFactory->BookMethod( TMVA::Types::kBDT, name.str().c_str(), opts.str().c_str() );\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training complete\n"
     ]
    }
   ],
   "source": [
    "###############################################\n",
    "# Train the network\n",
    "###############################################\n",
    "\n",
    "\n",
    "from rep.estimators import TMVAClassifier\n",
    "\n",
    "train_data = pandas.concat([data_train_signal, data_train_bkg], axis=0)\n",
    "train_labels = numpy.concatenate((numpy.ones(len(data_train_signal)), numpy.zeros(len(data_train_bkg))), axis=0)\n",
    "\n",
    "if \"EqualSigBck\" == training_mix:\n",
    "    k = 1. * len(data_train_signal)/len(data_train_bkg)\n",
    "else:\n",
    "    k = 1.\n",
    "    \n",
    "sample_weight = numpy.concatenate((numpy.ones(len(data_train_signal)), \n",
    "                                    k * numpy.ones(len(data_train_bkg))), axis=0)\n",
    "\n",
    "tmva.fit(train_data, train_labels, sample_weight=sample_weight)\n",
    "print('training complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.40007603e-01   7.59992397e-01]\n",
      " [  6.82554549e-04   9.99317445e-01]\n",
      " [  1.62450633e-01   8.37549367e-01]\n",
      " ..., \n",
      " [  4.23947763e-01   5.76052237e-01]\n",
      " [  1.92293868e-01   8.07706132e-01]\n",
      " [  2.25337797e-01   7.74662203e-01]]\n"
     ]
    }
   ],
   "source": [
    "test_data = pandas.concat([data_test_signal, data_test_bkg], axis=0)\n",
    "test_labels = numpy.concatenate((numpy.ones(len(data_test_signal)), numpy.zeros(len(data_test_bkg))), axis=0)\n",
    "\n",
    "prob = tmva.predict_proba(test_data)\n",
    "print prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC 0.909843132801\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print 'ROC AUC', roc_auc_score(test_labels, prob[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
